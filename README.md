**ğŸ¤– GenAI Chatbot**

A **Generative AI** chatbot built with **LangChain + Python**, deployed using **Streamlit**, and powered by the** GROQ LLM **for ultra-fast inference.
This project demonstrates how to build a stateful conversational AI system with memory, role-based messages, and persistent chat history. 

**ğŸš€ Features**
* ğŸ”— LangChain-based LLM orchestration
* âš¡ GROQ LLM integration for low-latency responses
* ğŸ§  Persistent chat memory using Streamlit session state
* ğŸ‘¥ Role-based conversations (User â†” Assistant)
* ğŸŒ Streamlit UI for real-time interaction

**ğŸ› ï¸ Tech Stack**
* LLM <-> GROQ
* Framework <-> LangChain
* Python
* Streamlit

**ğŸ’¡ Key Concepts & Code Design**

**1ï¸âƒ£ Role-Based Chat System**

The chatbot uses structured messages with explicit roles (user, assistant) to maintain conversational context. 
_st.session_state.chat_message = [
    {"role": "user", "content": user_input},
    {"role": "assistant", "content": response}
]_

**2ï¸âƒ£ Persistent Chat Memory**

To simulate â€œmemory,â€ the chatbot stores all previous exchanges using:
__st.session_state.chat_history.append(
    {"role": "user", "content": user_input}
)_ & 
_st.session_state.chat_history.append(
    {"role": "assistant", "content": response}
)_

This program prevents the chatbot from â€œforgettingâ€ earlier messages and enables contextual follow-up questions. 

**3ï¸âƒ£ Streamlit Session State Management**

Streamlit reruns the script on every interaction. Without _st.session_state_, chat history would reset on every user input. 

_if "chat_history" not in st.session_state:
    st.session_state.chat_history = []_

**â–¶ï¸ Running the Project**

_git clone https://github.com/g-diasha/genai-chatbot.git_

_cd genai-chatbot_

_pip install -r requirements.txt_

_streamlit run app.py_

**ğŸ” Environment Variables**
A .env file is created to protect the GROQ API KEY. 

_GROQ_API_KEY=my_api_key_here_


















